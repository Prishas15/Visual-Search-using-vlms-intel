# Visual Search using CLIP

This project implements a visual search system using OpenAI's CLIP model. The backend is built with FastAPI, and the frontend is developed using React.js.

## Features
âœ… Upload images to the backend
âœ… Search for similar images using text queries
âœ… Uses FAISS for efficient image retrieval

---

## ğŸ›  Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/your-username/vlm-visual-search.git
cd vlm-visual-search
```

### 2ï¸âƒ£ Install Backend Dependencies
```sh
cd backend
pip install -r requirements.txt
```

### 3ï¸âƒ£ Start Backend Server
```sh
uvicorn main:app --reload
```

### 4ï¸âƒ£ Install Frontend Dependencies
```sh
cd ../frontend
npm install
```

### 5ï¸âƒ£ Start Frontend
```sh
npm start
```

---

## ğŸš€ API Endpoints
### ğŸ“Œ Upload an Image
```
POST /upload/
```
- Uploads an image and extracts its embedding.

### ğŸ“Œ Search for Images
```
GET /search/?query=<text>
```
- Searches for images matching a text description.

---

## ğŸ“¦ Deployment
You can deploy the backend using **Docker**:
```sh
cd backend
docker build -t vlm-backend .
docker run -p 8000:8000 vlm-backend
```
For frontend deployment, use **Vercel** or **Netlify**.

---

## ğŸ“ License
This project is licensed under the MIT License.

---

Need help? Open an issue! ğŸš€
